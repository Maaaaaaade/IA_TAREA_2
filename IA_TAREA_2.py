# -*- coding: utf-8 -*-
"""IA_TAREA_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17OVcQEiTJMulQItY0hY8O-ptxEA6nUYd

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Madeleine Guzmán

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

---
## Antes de ejecutar el código, activar el uso de GPU en Google Colab.

* Ir a "Entorno de Ejecución" en el menú superior
* Haga click en "Cambiar tipo de entorno de ejecución"
* Seleccionar "T4 GPU" en "Acelerador de Hardware"
---

---
# Clasificación de dígitos
---

El problema que veremos será la clasificación de dígitos, con el dataset *Optical Recognition of Handwritten Digits Data Set* que contiene imágenes de 8x8 pixeles con dígitos manuscritos. El objetivo es lograr reconocer a que dígito corresponde cada muestra o imágen.

# Subir archivos

Cargaremos el dataset de forma remota con `wget` desde un repositorio de GitHub. Así podremos acceder al dataset solo con ejecutar las siguientes lineas, ya que este descarga los archivos directamente en el ambiente de Colab.
"""

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt

"""# Cargar dataset"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix

# Cargar conjuntos de datos de entrenamiento y prueba
column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_test = pd.read_csv('1_digits_test.txt', names = column_names)

"""> **Nota:** Con *head()* podemos ver las primeras 5 muestras o filas de un DataFrame."""

df_train_val.head()

df_test.head()

"""Vemos que tenemos 64 características más la columna de clases. Estas características corresponden a los pixeles que conforman las imágenes de 8x8, por ello el dataset tiene 64 dimensiones.

## Dividimos los datos de entrenamiento en validación y entrenamiento.
"""

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)
print("Muestras de entrenamiento: ", len(df_train))
print("Muestras de validación: ", len(df_val))
print("Muestras de prueba: ", len(df_test))
print("Muestras totales: ", len(df_train_val)+len(df_test))

"""## Normalización de los datos"""

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])
df_train.head()

"""# Dataloaders para utilizar los datos en PyTorch"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""# Entrenamiento de la red
En el siguiente código entrenamos el modelo anterior por 1000 epocas, procesando cada batch o lote en el que los dataloaders particionaron los datos. A lo largo del entrenamiento, calculamos la perdida (loss) de la red para poder visualizar su rendimiento luego.

#Modelo de una capa oculta con 10 neuronas y activación ReLU#
"""

#Definición del modelo a utilizar:
model_a = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_a = model_a.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_a.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_a(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_a(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_a(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_a(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Modelo de una capa oculta con 40 neuronas y activación ReLU#"""

#Definición del modelo a utilizar:
model_b = nn.Sequential(
          nn.Linear(64, 40),
          nn.ReLU(),
          nn.Linear(40,10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_b = model_b.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_b.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_b(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_b(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_b(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_b(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Modelo de una capa oculta con 10 neuronas y activación Tanh#"""

#Definición del modelo a utilizar:
model_c = nn.Sequential(
          nn.Linear(64, 10),
          nn.Tanh(),
          nn.Linear(10,10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_c = model_c.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_c.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_c(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_c(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_c(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_c(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Modelo de una capa oculta con 40 neuronas y activación Tanh#"""

#Definición del modelo a utilizar:
model_d = nn.Sequential(
          nn.Linear(64, 40),
          nn.Tanh(),
          nn.Linear(40,10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_d = model_d.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_d.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_d(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_d(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_d(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_d(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Modelo de dos capas ocultas con 10 neuronas en cada una y activación ReLU#"""

#Definición del modelo a utilizar:
model_e = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10),
          nn.ReLU(),
          nn.Linear(10, 10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_e = model_e.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_e.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_e(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_e(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_e(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_e(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Modelo de dos capas ocultas con 40 neuronas en cada una y activación ReLU#"""

#Definición del modelo a utilizar:
model_f = nn.Sequential(
          nn.Linear(64, 40),
          nn.ReLU(),
          nn.Linear(40,40),
          nn.ReLU(),
          nn.Linear(40, 10)
        )

#Se le indica a Pytorch que correremos el modelo con GPU:
device = "cuda" if torch.cuda.is_available() else "cpu"
model_f = model_f.to(device)

#Definimos la función de pérdida y optimizador usaremos:
criterion = nn.CrossEntropyLoss() #Función de pérdida
optimizer = torch.optim.Adam(model_f.parameters(), lr=1e-3) #Optimizador


start = time.time()
#Guardamos resultados del loss y epocas que duró el entrenamiento:
loss_train = []
loss_val = []
epochs = []
best_val_loss = float('inf')
counter = 0
patience = 10

#Entrenamiento de la red por n épocas:
for epoch in range(1000):

  #Guardar loss de cada batch:
  loss_train_batches = []
  loss_val_batches = []

  #Conjunto de Entrenamiento: --------------------------------------------------
  #Debemos recorrer cada batch (lote de los datos):
  for i, data in enumerate(dataloader_train, 0):
    #Procesar batch actual
    inputs = data["features"].to(device) #Características
    labels = data["labels"].to(device) #Clases
    #zero the parameter gradients
    optimizer.zero_grad()
    #forward + backward + optimize
    outputs = model_f(inputs) #Predicciones
    loss = criterion(outputs, labels) #Loss de entrenamiento
    loss.backward() #Backpropagation
    optimizer.step()

    #Guardamos la pérdida de entrenamiento en el batch actual:
    loss_train_batches.append(loss.item())

  #Guardamos el loss de entrenamiento de la época actual:
  loss_train.append(np.mean(loss_train_batches)) #Loss promedio de los batches


  #Predicción en Conjunto de Validación: ----------------------------------------
  with torch.no_grad():
    #Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      #Procesar batch actual
      inputs = data["features"].to(device) #Características
      labels = data["labels"].to(device) #Clases

      outputs = model_f(inputs) #Obtenemos predicciones

      #Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())

  #Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) #Loss promedio de los batches

  #Guardamos la época
  epochs.append(epoch)

  #Imprimimos la pérdida de entrenamiento/validación en la época actual:
  print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, loss_train[epoch], loss_val[epoch])))

  #Tenemos el loss de entrenamiento y validación, ¿Cómo sería el early-stopping?

  #Comprobamos si el loss de validación ha mejorado:
  if loss_val[-1] < best_val_loss:
     best_val_loss = loss_val[-1]
     counter = 0

  else:
     counter += 1

  #Verificamos si se debe detener el entrenamiento:
  if counter >= patience:
     print("Early stopping: No improvement in validation loss for %d epochs." % patience)
     break  #Se detiene el entrenamiento

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))


#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Entrenamiento)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_train, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_f(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Entrenamiento: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Entrenamiento (Precisión: {accuracy:.2f})")
plt.show()



#Después de finalizar el bucle de Entrenamiento: (Utilizando conjunto de Validación)
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_val, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_f(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Validación: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Prediccion")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Validación (Precisión: {accuracy:.2f})")
plt.show()


#Graficamos loss de entrenamiento y validación:
plt.figure(figsize = (8, 6))
plt.title("Pérdida del modelo en el Entrenamiento y la Validación")
plt.xlabel("Número de Épocas")
plt.ylabel("Pérdida")
plt.plot(epochs, loss_train, "b", label = "Entrenamiento", color = "purple")
plt.plot(epochs, loss_val, "r", label = "Validación", color = "hotpink")
plt.grid()
plt.legend()

"""#Mejor red encontrada en Validación: **Modelo de una capa oculta con 40 neuronas y activación ReLU (Precisión: 98%)**#"""

#Predicciones en el conjunto de Prueba:
with torch.no_grad():
    all_predicted_labels = [] #Almacenar todas las etiquetas predichas
    all_true_labels = [] #Almacenar todas las etiquetas verdaderas

    for i, data in enumerate(dataloader_test, 0):
        #Procesamos batch actual:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)

        outputs = model_b(inputs)

        #Obtenemos las etiquetas predichas:
        predicted_labels = torch.argmax(outputs, dim=1)

        all_predicted_labels.extend(predicted_labels.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())


#Calculamos la Precisión:
accuracy = accuracy_score(all_true_labels, all_predicted_labels)
print("Precisión en los datos de Prueba: %.4f" % accuracy)

#Calculamos la Matriz de Confusión:
confusion = confusion_matrix(all_true_labels, all_predicted_labels, normalize = "true")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot = True, cmap = "RdPu", fmt = ".2f")
plt.xlabel("Etiquetas de Predicción")
plt.ylabel("Etiquetas Verdaderas")
plt.title(f"Matriz de Confusión para Prueba (Precisión: {accuracy:.2f})")
plt.show()